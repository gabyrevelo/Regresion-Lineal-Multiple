---
title: "REGRESION LINEAL MULTIPLE"
author: "Gabriela E. Revelo B."
date: "2 de agosto de 2015"
output: html_document
---
### Introducción

En el presente documento se pretende generar un __informe dinámico__
en el cual se detalla cada uno de los pasos ejecutados en la generación del modelo de regresión lineal múltiple, las conclusiones y resultados obtenidos.

### Descripción 

Comenzamos generando un archivo rlm.R para luego leer los archivos: poblacion1.xlsx y poblacion2.xlsx (bases de datos) propuestos en este trabajo, se deben unir estas dos bases de datos en una sola data llamada poblacion, por lo que es útil ejecutar el comando __merge__ para ello eliminaremos la primera columna que es el identificador y nos quedaremos con los datos a analizar.

```{r,echo=TRUE,eval=TRUE}
options(warn=-1)
library(readxl)
library(ggplot2)
library(DT)
data1 <- read_excel("poblacion1.xlsx",sheet=1,na="")
data2 <- read_excel("poblacion2.xlsx",sheet=1,na="")

poblacion <- merge(x = data1 ,y = data2, by = "identificador", suffixes = c("","")) 
poblacion <- poblacion[,-1]
```
Nuestra nueva data es:
```{r,echo=TRUE,eval=TRUE}
datatable(poblacion)
```
Apliquemos ahora los siguientes comandos para obtener el modelo de regresión lineal múltiple.
```{r,echo=TRUE,eval=TRUE}
clase<-sapply(poblacion,class)
poblacion_reg<-poblacion[,clase=="numeric"]
regresion<-lm(poblacion~.,poblacion_reg)
```
Los resultados de esta regresión lineal múltiple son:
```{r,echo=TRUE,eval=TRUE}
summary(regresion)
```
Como se puede observar existen algunos regresores que son practicamente cero. Por lo que tenemos que analizar cual de las variables son mas representativas en nuestro modelo de regresión lineal múltiple.
Para ello:
```{r,echo=FALSE,eval=TRUE}
(regre<-step(regresion,direction="backward"))
```
Se puede observar que nuestro modelo de regresión lineal múltiple se redujo a un modelo de regresión lineal simple. Es este caso la variable __tasa.crimen__  es la mas representativa. Por tanto nuestro modelo de regresión se dispone de la siguiente manera:

$$\hat{`r substring(names(poblacion)[1],1,4)`} = `r regre$coefficients[1]` + (`r regre$coefficients[2]`)  \hat{`r substring(names(poblacion)[6],1,7)`}$$

### Interpretación

__Interpretación modelo de regresión lineal múltiple:__ Si `r names(poblacion)[6]` se incrementa en una unidad, entonces `r names(poblacion)[1]`
`r tex <-"disminuye"; if(regre$coefficients[2]<0) (tex<-"disminuye");tex` en promedio `r regre$coefficients[2]` unidades.

__Interpretación $R^2$:__ _El modelo de regresión lineal que se obtiene explica el `r paste(100*summary(regre)$r.squared,"%")` de la variabilidad total._

### Intervalos de confianza
```{r}
confint(regre,level = 0.95)
```
Al 95% de confianza los valores son distintos de cero; por lo tanto se rechaza la hipotesis inicial, esto se cumple para los dos casos.

### Gráficos residuales
```{r}
residuo <- regre[["residuals"]]
prediccion <- regre[["fitted.values"]]
data<- data.frame(poblacion[,"poblacion"],poblacion[,"tasa.crimen"], prediccion,residuo)
datatable(data,filter="top", options = list(
  searching = TRUE,
  pageLength = 5,
 lengthMenu = c(5, 10, 15)
 ))
```

```{r, fig.align="center",fig.width=5,fig.height=4}
hist(residuo,15)
mean(residuo)
qqnorm(residuo)
qqline(residuo,col="red")
plot(poblacion[,"tasa.crimen"],poblacion[,"poblacion"])
plot(residuo,prediccion)
plot(residuo,poblacion[,"tasa.crimen"])
```

### Conclusiones

1.La mayoría de los regresores en el modelo de regresión lineal múltiple fueron aproximadamente cero,fue por esta razón que el modelo de regresión múltiple se redujo a un modelo de regresión simple.

2.El modelo de regresión lineal múltiple puede ser reducido a un modelo de regresión lineal simple utilizando la variable __tasa.crimen__ como único regresor, ya que dicha variable es la mas representativa, se omiten las demas variables en el modelo ya que sus aportes no son significativos.

3.Se pretendió explicar la variable dependiente __poblacion__ en función de la variable explicativa __tasa.crimen__ mediante un modelo de regresión lineal simple. 

4.Una vez que se redujo el modelo, se determinaron las hipótesis nula para el intercepto y para el regresor, como cada una de ellas fueron rechazadas, entonces, se aceptó que tanto el regresor como el intercepto eran distintos de cero.
 
4.La media de los residuos fue 4.428153e-17, por tanto se cumplen los supuestos bajo las hipótesis N.

5.Necesitamos mas observaciones para deducir este modelo, los 40 datos de la data no fueron suficientes para determinar un buen modelo.

6.Cuando se analizó la gráfica de los residuos, estos puntos se encontraban dentro de una franja, por lo que no son vulnerables para nuestras hipótesis.

